<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Seyed A. Esmaeili</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Seyed A. Esmaeili
                </p>
                <p>I'm a Postdoctoral Researcher at the <a href="https://datascience.uchicago.edu/">Data Science Institute at the University of Chicago</a> where I am hosted by <a href="https://www.haifeng-xu.com/">Haifeng Xu</a>.
                </p>

 

                <p>Previously I was a Postdoctoral Fellow at the <a href="https://www.slmath.org/">Simons Laufer Mathematical Sciences Institute (SLMath)</a> at Berkeley where I was affiliated with the <a href="https://www.slmath.org/programs/353#overview_programs">Algorithms, Fairness, and Equity</a> program.</p>

                <p>Before that I was a CS PhD student at the <a href="https://www.cs.umd.edu/">University of Maryland</a> where I worked with <a href="http://jpdickerson.com/">John P. Dickerson</a> and <a href="http://www.cs.umd.edu/~srin/">Aravind Srinivasan</a>.</p>

                
                <p><b>Email</b>: last_name@uchicago.edu</p>


              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Seyed_image.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Seyed_image.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                I'm interested in <b>machine learning</b>, <b>algorithmic fairness</b>, and <b>strategic and game theoretic aspects of machine learning</b>. More specifically, I have worked on <b>fair clustering</b>, <b>redistricting/gerrymandering</b>, and <b>game-theoretic/strategic issues in multi-armed bandits</b>. Recently, I've been working on the <b>applications of generative AI in game-theoretic settings as well as studying their social impacts</b>. 
                </p>

              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Academic and Research Service</h2>
                <h3>Organizer and Program Chair: <span style="font-weight: normal;"> AAAI Workshop on <a href="https://markets-incentives-genai.github.io/"  style="font-size: inherit; font-weight: inherit;">Markets, Incentives, and Generative AI</a> </span></h3>
                <h3>Organizer and Presenter: <span style="font-weight: normal;"> AAAI Tutorial on <a href="https://www.fairclustering.com/"  style="font-size: inherit; font-weight: inherit;">Fair Clustering</a> </span></h3>
                <h3>Reviewer for various iterations of: <span style="font-weight: normal;">NeurIPS, ICML, ICLR, AAAI, AISTATS, FAccT, TMLR </span></h3>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected Publications</h2>
                <p class="note">
    -(<i>&alpha;</i>,<i>&beta;</i>) denotes alphabetical ordering.
    </p>

    <p class="note">
    -* denotes equal contribution.
    </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




    <br>




    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/data_auctions_2.png" width="350" alt="data_auctions">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <!--<a href="">-->
          <span class="papertitle">Data Auctions for Retrieval Augmented Generation</span>
        <br>
        </a>
    <a href="https://people.cs.uchicago.edu/~minbiaohan/">Minbiao Han*</a>,
    <strong>Seyed A. Esmaeili*</strong>,
    <a href="https://www.michaelalbert.co/">Michael Albert</a>,
    <a href="https://www.haifeng-xu.com/">Haifeng Xu</a>
        <br>
        <em>Under Review</em>, 2025.
        <br>
        <p> 
          Motivated by data selling for RAG based applications, we introduce a novel value function to measure the value of a dataset for each buyer. We then design a welfare maximizing algorithm with approximation guarantees. Additionally, we show how this algorithm can be further processed to lead to an incentive-compatible mechanism without degrading its approximation ratio.  
        </p>
      </td>
    </tr>


    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/interaction.jpg" width="250" alt="rfcng">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2406.05187">
          <span class="papertitle">How to Strategize Human Content Creation in the Era of GenAI?</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>, 
    <a href="https://research.google/people/kshipra-bhawalkar/">Kshipra Bhawalkar</a>,
    <a href="https://zfengharvard.github.io/">Zhe Feng</a>,
    <a href="https://dw236.github.io/">Di Wang</a>,
    <a href="https://www.haifeng-xu.com/">Haifeng Xu</a>
        <br>
        <em>Under Review</em>, 2025.
        <br>
        <p> 
         We introduce a novel model to study the competition between a human contributor and a GenAI agent in an online content creation platform. We focus on strategies that maximize the human contributor's utility. We design novel algorithms with theoretical guarantees to maximize the human's utility under various settings. Interestingly, we show that some settings exhibit computational hardness whereas others do not.          </p>
      </td>
    </tr>










    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/general.png" width="260" alt="rfcng">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2406.00599">
          <span class="papertitle">Robust Fair Clustering with Group Membership Uncertainty Sets</span>
        <br>
        </a>
    <a href="https://trinity24.github.io/">Sharmila Duppala</a>,
    <a href="https://www.linkedin.com/in/jdluque/">Juan Luque</a>,
    <a href="https://jpdickerson.com/">John Dickerson</a>,
    <strong>Seyed A. Esmaeili</strong>
        <br>
        <em>AISTATS</em>, 2025.
        <br>
        <p> 
        We study the canonical fair clustering problem when the group memberships are not perfectly known. Specifically, we introduce an interpretable family of error models that require little input from the decision maker and use robust optimization to produce algorithms with theoretical guarantees.    
        </p>
      </td>
    </tr>




    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/welfare.png" width="300" alt="welfare">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <!--<a href="">-->
          <span class="papertitle">Welfare-Centric Clustering</span>
        <br>
        </a>
    <a href="https://sites.google.com/view/claire-zhang">Claire Jie Zhang*</a>,
    <strong>Seyed A. Esmaeili*</strong>,
    <a href="https://jamiemorgenstern.com/">Jamie Morgenstern</a>
    <br>
        <em>Under Review</em>, 2025.
        <br>
        <p> 
          We introduce a new welfare-centric formulation to fair clustering based on clearly defined utilities. Our formulation leads to simpler and more intuitive solutions. We additionally, introduce algorithms with theoretical guarantees for this new formulation. 
        </p>
      </td>
    </tr>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/SAMF.png" width="275" alt="SAMF">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2312.07929">
          <span class="papertitle">Robust Performance Incentivizing Algorithms for Multi-Armed Bandits with Strategic Agents</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://suhoshin.github.io/">Suho Shin</a>,
    <a href="https://www.microsoft.com/en-us/research/people/slivkins/">Aleksandrs Slivkins</a>
        <br>
        <em>AAAI </em>, 2025.
        <br>
        <p>
        We study a variant of the multi-armed bandits problem where the arms are strategic and have control over their output level. We give algorithms that achieve the three objectives of learning, performance incentivization, and robustness simultaneously.   
        </p>
      </td>
    </tr>


    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/single.jpg" width="250" alt="replication_proof">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2312.16896">
          <span class="papertitle">Replication-Proof Bandit Mechanism Design</span>
        </a>
        <br>
    <a href="https://suhoshin.github.io/">Suho Shin</a>,
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://www.cs.umd.edu/~hajiagha/">MohammadTaghi Hajiaghayi</a>
        <br>
        <em>AAAI</em>, 2025.
        <br>
        <p>
        We study a bandit setting where agents can possibly register an unbounded number of arms. The agents have Bayesian priors over the arms' quality levels (means) but do not see the realizations of the means before registration. We show that prior work fails in this setting and give algorithms that are replication-proof.
        </p>
      </td>
    </tr>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/fig_fcc.png" width="300" alt="FCC">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2406.15960">
          <span class="papertitle">Fair Clustering: Critique, Caveats, and Future Directions</span>
        </a>
        <br>
    <sup>(<i>&alpha;</i>,<i>&beta;</i>)</sup>
    <a href="https://jpdickerson.com/">John Dickerson</a>,
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://jamiemorgenstern.com/">Jamie Morgenstern</a>,
    <a href="https://sites.google.com/view/claire-zhang">Claire Jie Zhang</a>,
        <br>
        <em>IEEE SaTML</em>, 2025.
        <br>
        <p>
        We identify a collection of shortcomings in the fair clustering literature and show a set of examples where the application of a fair clustering algorithm could possibly even degrade the welfare. Finally, we give some recommendations that could lead to more impactful fair clustering research.   
        </p>
      </td>
    </tr>










	










    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/redist_NC.png" width="250" alt="redist_nc">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2203.00872">
          <span class="papertitle">Implications of Distance over Redistricting Maps: Central and Outlier Maps</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://darshanc.com/">Darshan Chakrabarti</a>,
    <a href="https://www.linkedin.com/in/hayley-grape/">Hayley Grape</a>,
    <a href="https://bbrubach.github.io/">Brian Brubach</a>
        <br>
        <em>AAAI <font color="red"><strong>(Oral Presentation)</strong></font></em>, 2024.
        <br>
        <p>
        We introduce a simple and interpretable distance measure over redistricting maps. This enables us to select a <q>central</q> map that mirrors the Kemeny ranking in a scenario where a committee votes over a collection of maps. A byproduct of our framework is the possible detection of gerrymandered maps as we show that some instances are outliers in terms of distance. Our framework has significant computational speedups in comparison to prior work.  
        </p>
      </td>
    </tr>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/doubly_constrined.png" width="250" alt="doubly_constrined">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openreview.net/pdf?id=tECyQO1QOp">
          <span class="papertitle">Doubly Constrained Fair Clustering</span>
        </a>
        <br>
    <sup>(<i>&alpha;</i>,<i>&beta;</i>)</sup>
    <a href="https://jpdickerson.com/">John Dickerson</a>,
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://jamiemorgenstern.com/">Jamie Morgenstern</a>,
    <a>Claire Jie Zhang</a>
        <br>
        <em>NeurIPS</em>, 2023.
        <br>
        <p>
        The fair clustering literature has produced a large number of fairness notions and has largely ignored how these notions might be satisfied simultaneously or how they relate to one another. In this project, we choose two specific group representation-based fairness notions and give algorithms that can satisfy both of them simultaneously. In addition, we show incompatibility between these two notions and a set of distance-based fairness notions.
        </p>
      </td>
    </tr>


    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/fair_matching_2.png" width="250" alt="fair_matching">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2201.06021">
          <span class="papertitle">Rawlsian Fairness in Online Bipartite Matching: Two-sided, Group, and Individual</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://trinity24.github.io/">Sharmila Duppala</a>,
    <a >Davidson Cheng</a>,
    <a href="https://nvedant07.github.io/">Vedant Nanda</a>,
    <a href="https://www.cs.umd.edu/~srin/">Aravind Srinivasan</a>,
    <a href="https://jpdickerson.com/">John Dickerson</a>
        <br>
        <em>AAAI</em>, 2023.
        <br>
        <p>
        We consider an online matching platform and show algorithms that give fairness guarantees for the two sides to be matched as well as a revenue guarantee for the platform operator. We further establish lower bounds on the performance of any algorithm and show that in general individual and group fairness can be at odds with one another.
        </p>
      </td>
    </tr>




    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/equitable.png" width="250" alt="equitable">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2106.05423">
          <span class="papertitle">A New Notion of Individually Fair Clustering:<i>&alpha;</i>-Equitable k-Center</span>
        </a>
        <br>
    <sup>(<i>&alpha;</i>,<i>&beta;</i>)</sup>
    <a href="https://darshanc.com/">Darshan Chakrabarti</a>,
    <a href="https://jpdickerson.com/">John Dickerson</a>,
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://www.cs.umd.edu/~srin/">Aravind Srinivasan</a>,
    <a href="https://www.ltsepene.com/">Leonidas Tsepenekas</a>,
        <br>
        <em>AISTATS</em>, 2022.
        <br>
        <p>
        We introduce a new notion of individual fairness in clustering which constraints the solution to have equitable distance to center values across the points. We establish lower bounds on our new clustering problem, study its price of fairness, and give approximation algorithms for it. 
        </p>
      </td>
    </tr>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/lfc.jpeg" width="250" alt="lfc">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2205.14358">
          <span class="papertitle">Fair Labeled Clustering</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://trinity24.github.io/">Sharmila Duppala</a>,
    <a href="https://jpdickerson.com/">John Dickerson</a>,
    <a href="https://bbrubach.github.io/">Brian Brubach</a>
        <br>
        <em>KDD</em>, 2022.
        <br>
        <p>
        We consider a setting where different clusters have outcomes of possibly varying qualities (labels) associated with them. We show that unlike previous work, fairness considerations are more affectively satisfied by having close to population level proportional representation of each group across the label not the clusters. We further give algorithms with theoretical guarantees for this setting.
        </p>
      </td>
    </tr>


    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/FCBC_1.png" width="250" alt="FCBC">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2106.07239">
          <span class="papertitle">Fair Clustering Under a Bounded Cost</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://bbrubach.github.io/">Brian Brubach</a>,
    <a href="https://www.cs.umd.edu/~srin/">Aravind Srinivasan</a>,
    <a href="https://jpdickerson.com/">John Dickerson</a>
        <br>
        <em>NeurIPS</em>, 2021.
        <br>
        <p>
        Imposing a fairness constraint on clustering may lead to an unbounded degradation in the clustering cost. Therefore, in this project we introduce a new problem where we maximize the amount of <q>fairness</q> subject to an upper bound on the clustering cost. We define appropriate fairness measures and give algorithms with guarantees for them.
        </p>
      </td>
    </tr>


    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/pfc_cover.png" width="250" alt="pfc">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2006.10916">
          <span class="papertitle">Probabilistic Fair Clustering</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>,
    <a href="https://bbrubach.github.io/">Brian Brubach</a>,
    <a href="https://www.ltsepene.com/">Leonidas Tsepenekas</a>,
    <a href="https://jpdickerson.com/">John Dickerson</a>
        <br>
        <em>NeurIPS</em>, 2020.
        <br>
        <p>
        We study the fair clustering problem when the group memberships are imperfectly known. Specifically, we consider the fairness notion where each cluster is supposed to have close to population level proportion of each group in the setting where probabilistic instead of deterministic group membership knowledge is available. We introduce a probabilistic fairness notion for this setting and give algorithms with theoretical guarantees to solve it.  
        </p>
      </td>
    </tr>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/DPTM.jpeg" width="275" alt="DPTM">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://proceedings.mlr.press/v119/decarolis20a/decarolis20a.pdf">
          <span class="papertitle">An end-to-end Differentially Private Latent Dirichlet Allocation Using a Spectral Algorithm</span>
        </a>
        <br>
    <a >C. DeCarolis</a>,
    <a >M. Ram</a>,
    <strong>Seyed A. Esmaeili</strong>,
    <a >Y. Wang</a>,
    <a >F. Huang</a>
    <br>
        <em>ICML</em>, 2020.
        <br>
        <p>
        We introduce a differentially private matrix/tensor-based spectral algorithm for Latent Dirichlet Allocation. We present the algorithm as a computational graph and study noise injection at different edges establishing utility guarantees for each different choice and showing that some can outperform others at different regimes.
        </p>
      </td>
    </tr>




    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/fast_at.jpeg" width="250" alt="FAST_AT">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/1612.04811.pdf">
          <span class="papertitle">Fast-AT: Fast Automatic Thumbnail Generation using Deep Neural Networks</span>
        </a>
        <br>
    <strong>Seyed A. Esmaeili</strong>,
    <a >Bharat Singh</a>,
    <a >Larry S. Davis</a>
    <br>
        <em>CVPR</em>, 2017.
        <br>
        <p>
        We solve the problem of automated thumbnail generation using a deep neural net achieving higher quality thumbnails with a faster run-time than previous method. We also introduce a dataset of images and their manually generated thumbnails.
        </p>
      </td>
    </tr>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>


  </body>
</html>
